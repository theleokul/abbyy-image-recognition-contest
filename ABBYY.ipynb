{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = 'test'\n",
    "mark_folder = 'mark'\n",
    "dump_file = 'predictions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulations with files\n",
    "\n",
    "def get_files_from_folder(folder):\n",
    "    return [os.path.join(folder, f) \n",
    "            for f in os.listdir(folder) \n",
    "            if re.match(r'.*\\.jpg', f, flags=re.I)]\n",
    "\n",
    "\n",
    "def get_class_img_from_file(file):\n",
    "    img = plt.imread(file)\n",
    "    cls = int(Path(file).stem.split('.')[0])\n",
    "    return cls, img\n",
    "\n",
    "\n",
    "def get_classes_imgs_from_folder(folder):\n",
    "    files = get_files_from_folder(folder)\n",
    "    classes, imgs = zip(*[get_class_img_from_file(f) for f in files])\n",
    "    return classes, imgs\n",
    "            \n",
    "            \n",
    "def get_batched_classes_imgs_from_folder(folder, batch_size):\n",
    "    files_batches = np.reshape(get_files_from_folder(folder), (-1, batch_size))\n",
    "    for fs_batch in fs_batches:\n",
    "        classes, imgs = zip(*[get_class_img_from_file(f) for f in fs_batch])\n",
    "        yield classes, imgs\n",
    "            \n",
    "            \n",
    "def dump_predictions(predicted_classes, questioned_classes, dump_file):\n",
    "    ext = np.array([predicted_classes, questioned_classes]).T\n",
    "    df_ext = pd.DataFrame(ext)\n",
    "    \n",
    "    if os.path.exists(dump_file):\n",
    "        df = pd.read_csv(dump_file)\n",
    "        df = df.append(df_ext, ignore_index=True)\n",
    "        df.to_csv(dump_file, index=False, columns=[])\n",
    "    else:\n",
    "        df_ext.to_csv(dump_file, index=False, columns=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face recognition prerequisites\n",
    "\n",
    "# Pretrained model for face detection\n",
    "mtcnn = MTCNN()\n",
    "# Pretrained model (VGGFace2) for face recognition\n",
    "face_spatial_shape = (224, 224)\n",
    "vggface2_net = VGGFace(model='resnet50', input_shape=(*face_spatial_shape, 3), pooling='avg')\n",
    "\n",
    "\n",
    "def get_face(detector, img, resize_to=(224, 224)):\n",
    "    try:\n",
    "        res = detector.detect_faces(img)\n",
    "        x1, y1, width, height = res[0]['box']\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        face = img[y1:y2, x1:x2]\n",
    "    except IndexError:\n",
    "        # In case if no faces are found\n",
    "        face = img\n",
    "    face = cv.resize(face, resize_to)\n",
    "    return face\n",
    "\n",
    "\n",
    "def get_faces(detector, imgs, resize_to=(224, 224)):\n",
    "    faces = []\n",
    "    for img in tqdm(imgs):\n",
    "        faces.append(get_face(detector, img, resize_to=resize_to))\n",
    "    return faces\n",
    "\n",
    "\n",
    "def get_encodings(model, faces):\n",
    "    p_faces = preprocess_input(faces, version=2)\n",
    "    encs = model.predict(p_faces)\n",
    "    return encs\n",
    "\n",
    "\n",
    "def get_class(questioned_enc, known_encs, known_classes):\n",
    "    norms = np.squeeze(np.linalg.norm(known_encs - questioned_enc[np.newaxis], axis=1))\n",
    "    return known_classes[np.argmin(norms)]\n",
    "\n",
    "\n",
    "def get_classes(questioned_encs, known_encs, known_classes):\n",
    "    return [get_class(q_enc, known_encs, known_classes) for q_enc in questioned_encs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 198/500 [05:45<09:49,  1.95s/it]"
     ]
    }
   ],
   "source": [
    "# Solve the actual problem\n",
    "\n",
    "# Pull known features\n",
    "known_classes, known_imgs = get_classes_imgs_from_folder(mark_folder)\n",
    "known_faces = get_faces(mtcnn, known_imgs, resize_to=face_spatial_shape)\n",
    "known_encodings = get_encodings(vggface2_net, known_faces)\n",
    "\n",
    "# Recognition\n",
    "batch_size = 20\n",
    "for q_classes, q_imgs in get_batched_classes_imgs_from_folder(folder, batch_size=batch_size):\n",
    "    q_faces = get_faces(detector, q_imgs, resize_to=face_spatial_shape)\n",
    "    q_encodings = get_encodings(vggface2_net, q_faces)\n",
    "    p_classes = get_classes(q_encodings, known_encodings, known_classes)\n",
    "    dump_predictions(p_classes, q_classes, dump_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
